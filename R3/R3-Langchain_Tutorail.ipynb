{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rag.jpeg\" alt=\"RAG架構\" width=\"45%\"/>\n",
    "\n",
    "依照上圖，RAG 的流程可以分成 5 大步驟\n",
    "1. **Document Loading:** 讀取補充 LLM 知識的參考資料\n",
    "2. **Splitting:** 將 Document 依照文字長短、段落、頁數等進行切分\n",
    "3. **Vector Storage:** 將切分的文字轉為 Embedding 後，儲存在向量資料庫\n",
    "4. **Retrival:** 找出與用戶問題相關的參考資訊\n",
    "5. **Q&A:** 利用 LLM 搭配參考資料來回答用戶的問題\n",
    "以下將就前 4 個步驟分別介紹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Loading\n",
    "Langchain 裡有非常不同類型的 Document Loader，以下簡單介紹三種不同類型的 loader\n",
    "\n",
    "其他範例可以參考：https://python.langchain.com/v0.2/docs/integrations/document_loaders/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "fiel_dir = \"PDF_DIRECTORY\"\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(fiel_dir)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 YouTube Video\n",
    "需要付費使用 OpenAI 的 Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir = \"docs/youtube/\"\n",
    "\n",
    "\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], save_dir),\n",
    "    OpenAIWhisperParser())\n",
    "video_docs = loader.load()\n",
    "video_docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 URLs (網路上的文章)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "url = \"https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm\"\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(url)\n",
    "news_docs = loader.load()\n",
    "news_docs[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理想上，如果載入資料之後不做任何處理就能給語言模型使用是最好的。\n",
    "\n",
    "不過語言模型能接受的 tokens 數量有限(或稱 context window)，所以不免要對 Document 做進一步的處理，將 Document 切成多個更小的區塊(chunk), 這個步驟是由 LangChain 的 Text Splitters 所提供，它的大致運作過程是：\n",
    "\n",
    "1. 將文本(text)切成多個小的且有語意的區塊(chunk)，通常是以句子為單位進行切塊，要注意過小的區塊容易喪失語意\n",
    "2. 將第 1 步所產生的多個區塊進行合併，合併成所設定的區塊長度(chunk size)\n",
    "3. 為了保留前後文(上下文)的情境，進一步產生含有 overlap 的區塊\n",
    "\n",
    "畫成圖表示的話，區塊就是下列樣貌，可以看到每個區塊會有重疊(overlap)，藉此保留前後文情境：\n",
    "\n",
    "<img src=\"images/chunks.png\" alt=\"Chunk\" width=\"25%\"/>\n",
    "\n",
    "**RecursiveCharacterTextSplitter 參數**\n",
    "1. Chunk Size: 每個分割的字元數\n",
    "\n",
    "2. Chunk Overlap: 連續的 chunk 之間重疊的字元數\n",
    "\n",
    "3. Separator:\n",
    "先以段落分割 → (若長度仍大於 chunk size) → 以換行符號分割 → (若長度仍大於 chunk size) → 以下一個分隔符號吐出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=30)\n",
    "texts_chunks = text_splitter.split_documents(news_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Embedding\n",
    "\n",
    "資訊有多種形式。有些資訊為非結構化資訊 (例如文字文件、多媒體和音訊)，有些則則是結構化資訊，例如應用程式日誌、資料表和圖形。\n",
    "\n",
    "Embedding 可將所有類型的資料編碼為向量，以擷取資產含義和內容。這讓我們能夠搜尋相鄰的資料點，藉此來尋找相似的內容。\n",
    "\n",
    "依據應用選擇合適的 Embedding 模型，可以參考 MTEB Leaderboard 挑選模型: https://huggingface.co/spaces/mteb/leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# 初始化 Embedding 模型\n",
    "embedding_func = HuggingFaceEmbeddings(\n",
    "    model_name=\"infgrad/stella-base-zh-v3-1792d\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True})\n",
    "\n",
    "# 將字句轉換為向量\n",
    "a = embedding_func.embed_query('突襲式發表！蘋果推 2 款 M3 MacBook Air，強調 AI 、遊戲效能皆強化')\n",
    "b = embedding_func.embed_query('蘋果最新M3版MacBook Air突襲登場！6亮點下放1技術不漲價 M2版還降3000元')\n",
    "\n",
    "# 計算相似度\n",
    "cosine_similarity([a], [b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Vectore Store\n",
    "\n",
    "向量資料庫是一種特殊類型的資料庫，專門設計用來處理、索引及搜尋非結構化資料。它不會以傳統的表格格式來組織資料，而是將資料排列成高維向量。這種獨特的結構可讓資料庫更有效率且更準確地處理複雜的多維資料。\n",
    "\n",
    "向量資料庫的關鍵功能之一，就是使用泛型 AI 來執行分析。這包括相似性搜尋，以及異常狀況偵測，藉此找出與正常情況大不相同的資料點。\n",
    "\n",
    "市場上存在很多不同的向量資料庫：Pinecone, Chroma, Weaviate 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(texts_chunks, embedding_func)\n",
    "\n",
    "# query it\n",
    "query = \"什麼是 LLM 模型？\"\n",
    "docs = db.similarity_search_with_score(query)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "MODEL_NAME = \"MediaTek-Research/Breeze-7B-Instruct-v0_1\"\n",
    "\n",
    "\n",
    "# 量化參數\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True)\n",
    "\n",
    "# llm 初始化\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=MODEL_NAME,\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs=dict(\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=quantization_config),\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.0001,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.15) )\n",
    "\n",
    "# Prompt 模板\n",
    "template = \"\"\"\n",
    "<s>\n",
    "請你做為一個大型語言模型的專家，並根據下方所提供的資訊，來回答使用者的提問。\n",
    "\n",
    "[INST]\n",
    "{context}\n",
    "\n",
    "{question}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt})\n",
    "\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "# LLM 提供的回答\n",
    "print(\"回覆：\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "# 參考的相關資訊\n",
    "print(\"參考資訊：\")\n",
    "print(result[\"source_documents\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
